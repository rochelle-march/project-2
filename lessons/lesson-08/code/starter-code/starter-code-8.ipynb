{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Practice: Logit Function and Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-6-10730b5b0431>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-10730b5b0431>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    def sigmoid_func(logit):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def logit_func(odds):\n",
    "    # uses a float (odds) and returns back the log odds (logit)\n",
    "\n",
    "def sigmoid_func(logit):\n",
    "    # uses a float (logit) and returns back the probability\n",
    "\n",
    "odds_set = [\n",
    "    5./1,\n",
    "    20./1,\n",
    "    1.1/1,\n",
    "    1.8/1,\n",
    "    1.6/1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logit_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7ed9ec180dd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logit_func' is not defined"
     ]
    }
   ],
   "source": [
    "# plot out the logit function and sigmoid function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "xaxis = np.linspace(0,1,60000)\n",
    "y = logit_func(xaxis)\n",
    "plt.plot(xaxis,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigmoid_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9fb76e2baa20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sigmoid_func' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "xaxis = np.linspace(-6,6,60)\n",
    "y = sigmoid_func(xaxis)\n",
    "plt.plot(xaxis,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "\n",
    "df = pd.read_csv('../../assets/dataset/collegeadmissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 4, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rank\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.join(pd.get_dummies(df['rank'],prefix=\"prestige\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "      <th>prestige_1</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank  prestige_1  prestige_2  prestige_3  prestige_4\n",
       "0      0  380  3.61     3           0           0           1           0\n",
       "1      1  660  3.67     3           0           0           1           0\n",
       "2      1  800  4.00     1           1           0           0           0\n",
       "3      1  640  3.19     4           0           0           0           1\n",
       "4      0  520  2.93     4           0           0           0           1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(df[['gre', 'gpa', \"prestige_1\", \"prestige_2\", \"prestige_3\",]], df['admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.63913356e-03   4.33354115e-04   1.15220976e+00   5.14395667e-01\n",
      "   -3.62326171e-02]]\n",
      "[-2.09315183]\n",
      "0.3175\n"
     ]
    }
   ],
   "source": [
    "print lm.coef_\n",
    "print lm.intercept_\n",
    "print df.admit.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some code to walk through confusion matrices. It'll be useful for working through the Titanic problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the ROC curve is based on various thresholds: it shows with a false positive rate (x-axis) ~0, it also expects a true positive rate (y-axis) ~0 (the same, ish, for the top right hand of the figure).\n",
    "\n",
    "The second chart, which does not play with thesholds, shows the one true TPR and FPR point, joined to 0,0 and 1,1.\n",
    "\n",
    "The first chart will be more effective as you compare models and determine where the decision line should exist for the data. The second simplifies the first in case this idea of thresholds is confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_set = df[['gre', 'gpa', \"prestige_1\", \"prestige_2\", \"prestige_3\",]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1119a9350>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkZekArPIS1KBWeQlqcAs8pJUYP8fmBzxmUmdsRoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11179bf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "actuals = lm.predict(feature_set) \n",
    "probas = lm.predict_proba(feature_set)\n",
    "plt.plot(roc_curve(df[['admit']], probas[:,1])[0], roc_curve(df[['admit']], probas[:,1])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the `roc_auc_score` function to calculate the area under these curves (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55914164575581893"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df['admit'], lm.predict(feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    admitted       0.71      0.95      0.81       273\n",
      "not-admitted       0.59      0.17      0.27       127\n",
      "\n",
      " avg / total       0.67      0.70      0.64       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print classification_report(df['admit'], lm.predict(feature_set), target_names=['admitted', 'not-admitted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Goals **\n",
    "\n",
    "1. Spend a few minutes determining which data would be most important to use in the prediction problem. You may need to create new features based on the data available. Consider using a feature selection aide in sklearn. But a worst case scenario; identify one or two strong features that would be useful to include in the model.\n",
    "2. Spend 1-2 minutes considering which _metric_ makes the most sense to optimize. Accuracy? FPR or TPR? AUC? Given the business problem (understanding survival rate aboard the Titanic), why should you use this metric?\n",
    "3. Build a tuned Logistic model. Be prepared to explain your design (including regularization), metric, and feature set in predicting survival using the tools necessary (such as a fit chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('../../assets/dataset/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "# Insert the code to do your fitting and prediction. Dont forget to include cross-validation\n",
    "# Try out different metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
